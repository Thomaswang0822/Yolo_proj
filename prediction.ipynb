{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file load the model into opencv, make preditions on new images, and construct the image with predicted bbox and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "import os\n",
    "from os.path import join as pjoin\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load data.yaml file (config)\n",
    "YOLO_DIR = \"yolov5-old/\"\n",
    "with open(pjoin(YOLO_DIR, 'data.yaml'), 'r') as f:\n",
    "    # this is a dict\n",
    "    data_yaml = yaml.load(f, Loader=SafeLoader)\n",
    "\n",
    "labels = list(data_yaml['names'])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load trained yolo model into opencv\n",
    "MODEL_DIR = \"./yolov5-old/runs/train/Model100_small/weights/best.onnx\"\n",
    "MODEL_TORCH_DIR = \"./yolov5-old/runs/train/Test10_small/weights/best.pt\"\n",
    "\n",
    "# yolov5 = cv2.dnn.readNetFromTorch(MODEL_PRE_DIR)\n",
    "yolov5 = cv2.dnn.readNetFromONNX(MODEL_DIR)\n",
    "\n",
    "# set computing engine\n",
    "yolov5.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "\n",
    "# make computations on device\n",
    "yolov5.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Load testing images\n",
    "# *** We can have variable size training images, but test images should be cropped to fixed sqaure size ***\n",
    "def load_img(fname, img_dir=\"./test_data\"):\n",
    "    orig_image = cv2.imread(pjoin(img_dir, fname))  # original image (to be compared with)\n",
    "    image = orig_image.copy()   # np ndarray\n",
    "    nrow, ncol, ch = image.shape\n",
    "    assert ch == 3, \"require testing image in RGB format\"\n",
    "\n",
    "    l = max(nrow, ncol)\n",
    "    img_input = np.zeros((l,l,3), dtype=np.uint8)   # black background board\n",
    "    img_input[:nrow, :ncol] = image     # fill in image\n",
    "    return img_input, orig_image, image    # paddled sqaure image for model input\n",
    "\n",
    "\n",
    "fname = \"000229.jpg\"\n",
    "img_input, orig_image, image  = load_img(fname)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Let the model make predictions\n",
    "def one_prediction(img_input, model, YOLO_IMG_SZ = (640, 640) ):\n",
    "    # YOLO_IMG_SZ: see export.py\n",
    "\n",
    "    # See: https://docs.opencv.org/4.x/d6/d0f/group__dnn.html#ga29f34df9376379a603acd8df581ac8d7\n",
    "    blob = cv2.dnn.blobFromImage(img_input, 1/255, YOLO_IMG_SZ, swapRB=True, crop=False)\n",
    "    model.setInput(blob)\n",
    "\n",
    "    # shape = (1, #bbox, 25), \n",
    "    # 25 = 5 {centerX, centerY, w, h, confidence} + 20 {prob score of each class}\n",
    "    pred = model.forward()\n",
    "    return pred[0]\n",
    "\n",
    "\n",
    "pred = one_prediction(image, yolov5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Non-maximum Suppression: \n",
    "## filter predictions of a single image based on confidence and prob score threshold\n",
    "## NMS removes duplicate bbox\n",
    "def nonmax_sup(pred, img_input, conf_thold=0.1, prob_thold=0.5, YOLO_IMG_WH=640):\n",
    "    # factors to restore shape info of testing image, which is not 640x640\n",
    "    x_factor, y_factor = img_input.shape[0]/YOLO_IMG_WH, img_input.shape[1]/YOLO_IMG_WH\n",
    "\n",
    "    conf_list, bbox_list, id_list = [], [], []\n",
    "    for row in pred:\n",
    "        conf = row[4]   # confidence of \"this bbox catch an object of whatever class\"\n",
    "        if conf > conf_thold:\n",
    "            tag_id = row[5:].argmax()   # id (0-19) of \"the most likely class/tag\"\n",
    "            prob_score = row[5:][tag_id]  # probability score of \"the most likely class/tag\"\n",
    "            if prob_score >= prob_thold:\n",
    "                # bbox info\n",
    "                cx, cy, w, h = row[:4]\n",
    "                # denormalize (restore to int) top-left position, width, height\n",
    "                width = int(w * x_factor)\n",
    "                height = int(h * y_factor)\n",
    "                x_left = int( (cx - 0.5*w) * x_factor)\n",
    "                y_top = int( (cy - 0.5*h) * y_factor)\n",
    "                bbox = [x_left, y_top, width, height]\n",
    "\n",
    "                # store info\n",
    "                conf_list.append(conf)\n",
    "                bbox_list.append(bbox)\n",
    "                id_list.append(tag_id)\n",
    "\n",
    "    # NMS\n",
    "    index = cv2.dnn.NMSBoxes(bbox_list, conf_list, conf_thold, prob_thold).flatten()\n",
    "\n",
    "    return index, conf_list, bbox_list, id_list\n",
    "\n",
    "\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index, conf_list, bbox_list, id_list = nonmax_sup(pred, img_input)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Draw bbox\n",
    "## We want each bbox to have a tag (word instead of id) and a probability\n",
    "img_input, orig_image, image  = load_img(fname)\n",
    "def draw_bbox():\n",
    "    for idx in index:\n",
    "        # retrieve info\n",
    "        x_left, y_top, width, height = bbox_list[idx]\n",
    "        conf = conf_list[idx] * 100\n",
    "        tag = labels[ id_list[idx] ]\n",
    "\n",
    "        # format text display\n",
    "        text = f\"{tag}: {conf:.1f}%\"\n",
    "        print(text)\n",
    "\n",
    "        # cv2.rectangle(image, top-left, bot-right, box colr, thickness)\n",
    "        GREEN = (0, 255, 0)\n",
    "        BLACK = (0, 0, 0)\n",
    "        cv2.rectangle(image, (x_left, y_top), (x_left+width, y_top+height), GREEN, 2)\n",
    "        cv2.putText(image, text, (x_left, y_top-10), cv2.FONT_HERSHEY_PLAIN, 0.8, BLACK, 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Original Image', orig_image)\n",
    "cv2.imshow('With Object Detection', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo_old",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b7fb410b38b7b83c89826596f037a1f44be681445659f02a132551fd686542cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
